FROM qwen2.5-coder:7b

# Context window: how many tokens the model can process at once
# Default is 2048. We bump to 16384 (16K) for working with larger code files.
# On 12GB VRAM with a 7B model (~4.9GB), we have headroom for this.
# Each doubling of context costs ~0.5-1GB extra VRAM at 7B scale.
PARAMETER num_ctx 16384

# Temperature: controls randomness (0.0 = deterministic, 1.0 = creative)
# 0.3 is ideal for code: precise enough for correct syntax,
# with just enough variation to suggest alternative approaches.
PARAMETER temperature 0.3

# Top-p (nucleus sampling): only consider tokens within the top P probability mass.
# 0.9 means "pick from tokens that together cover 90% probability."
# Combined with low temperature, this cuts off unlikely/garbage completions
# while still allowing the model to choose between reasonable alternatives.
PARAMETER top_p 0.9

# Repeat penalty: penalizes tokens that already appeared in the output.
# 1.0 = no penalty, >1.0 = discourage repetition.
# 1.1 is gentle enough to allow natural code patterns (e.g., repeated keywords)
# while preventing degenerate loops where the model gets stuck.
PARAMETER repeat_penalty 1.1

# Stop sequences: special tokens that signal "end of response."
# Qwen2.5 uses ChatML format internally. These are its native end markers.
# Without these, the model might hallucinate a new user turn or keep rambling.
PARAMETER stop "<|im_end|>"
PARAMETER stop "<|endoftext|>"

# System prompt: defines the model's persona, expertise, and output format.
# This is injected at the start of every conversation as a ChatML system message.
# Keep it focused â€” 7B models follow short, direct instructions better than long ones.
SYSTEM """You are an expert backend software engineer specializing in Java and Go.
You write clean, well-documented, production-ready code.
Follow SOLID principles and idiomatic language conventions.
When asked to write code, provide complete implementations with proper error handling.
Explain your reasoning when relevant.
Format all code in markdown code blocks with language tags."""
